---
title: "segmenteR's vignette"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{segmenteR_vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# segmenteR

segmenteR is a tool to extract a section, for example, "material and methods", from the pdf of an article, using the fonts information from the pdf and natural language processing.

This tool to segment articles that has been elaborated in the context of the Horizon 2020 project REFINE, a project aiming to develop a regulatory science framework for the risk-benefit assessment of medical products based on nanotechnology.

segmenteR has been developped at the Joint Research Centre, Directorate F - Health, Consumers and Reference Materials, Ispra (VA), Italy.

The project aimed to analyse a corpus of 821 articles, obtained from the PubMed MeSH database and related to several toxicity topics (cardiotoxicity, genotoxicity, etc), to evaluate the quality of the reporting of methods of characterization and to parse the articles for specifics toxicity effects and specifics nanoparticules.

In order to evaluate the quality of the reporting inside each articles and parse the texts for specific toxicity effects, we needed to extract both the material and methods section and the results section of each articles, respectively. The tool segmenteR was developed to carry this specific subtask of segmentating the articles into the differents sections.

If you use this tool, please cite to the following publication : Applying of automatic tools for a systematic review of safety effects of nanomedicines, Blanka Halamoda-Kenzaoui, Etienne Rolland, Jacopo Piovesan, Antonio Puertas Gallardo, Susanne Bremer-Hoffmann.

# Installation

To extract the information on the fonts inside the pdf we use poppler, a [PDF rendering library](https://poppler.freedesktop.org/) and the cpp API of poppler. 
The package require a **version of poppler >= 0.89** as well as a recent version of pdftools. 
segmenteR currently rely on a **dev version of pdftools** that integrate the later updates of poppler and poppler cpp, the cpp API of poppler to read the information about the fonts inside an article.

Currently install the tool you need install both :

```{r}
#devtools::install_github("Cdk29/pdftools") #until the PR is integrated into the main package
#devtools::install_github("Cdk29/segmenteR") 
```

# Main function :

"Abrams, M T et al 2010" is an article about the biodistribution profile of a nanoparticle for siRNA therapy. Due to the alphabetic ordering, it was the first article inside the first folder in the project in which segmenteR was developed, and since then it became the default demo/test article. The article is also in open-access :


```{r download_demo}
if (!file.exists('Abrams, M T et al 2010.pdf')) {
  url <- ('https://www.cell.com/action/showPdf?pii=S1525-0016%2816%2931594-5')
  download.file(url, 'Abrams, M T et al 2010.pdf')
}
```

The goal of the package is to extract one specific section of an article, such as material and methods, or results, for downstream analysis.
The generated output is a dataframe in the Conll-U format, generated by the udpipe package in R. This format, which contain the text annotated and tokenized, is suitable for other NLP application, such as parsing. For more details on this format and how to parse the results, please refer to the [the vignette of udpipe](https://cran.r-project.org/web/packages/udpipe/vignettes/udpipe-annotation.html).

In this example we want to extract the material and method section :

```{r setup}
library(segmenteR)

#the name of the section we want to extract
section_aliases <- c("material", "method", "experimental", "experiment", "methodology")

#model definition can be skipped, the function can download it automatically
model <- "english-gum-ud-2.4-190531.udpipe"
material_and_methods <- segmenteR::extract_section_from_pdf(pdf_name="Abrams, M T et al 2010.pdf",
                                                            udpipe_model=model, 
                                                            section_aliases=section_aliases)

head(material_and_methods)
```


# Step by step explanation :

This part of the vignette shows the internal working of the function extract_section_from_pdf.
After we set the default parameters of the function extract_section_from_pdf() (such as remove_bibliography), the first step is to extract the text from the pdf, using the function extract_text() from tabulizer. The reason why we choose tabulizer over other library is that it handle better the text of articles write in a two columns style. Repair_txt() apply a collection of regex to preprocess the text for downstream use.

```{r}
pdf_name <- "Abrams, M T et al 2010.pdf"
remove_bibliography <- TRUE

txt_pdf <- tabulizer::extract_text(pdf_name) # read the text from the pdf
txt_pdf <- segmenteR::preprocess_article_txt(txt_pdf)
substr(txt_pdf, 1, 100)
substr(txt_pdf, 101, 200)
substr(txt_pdf, 201, 300)
```

The role of the function annotate_txt_pdf() is to load the required model and use udpipe to tokenize and annotate the text. As you can see it output the Conll-U format we saw earlier in the vignette. The reason behind this annotation that we will need this information to estimate where is the most likely the section title. For example, if it is the first word of a sentence, if the the word of the sentence is also a section title, etc.

```{r}
conllu_df <- segmenteR::annotate_txt_pdf(txt_pdf, udpipe_model=model ) # create the dataframe for NLP using udpipe
head(conllu_df)
```
The other information we use, and the reason why we work directly on a pdf instead of a text, is the fonts information from the pdf, the font and fontsize of the words inside the pdf. To do this we use poppler, a [PDF rendering library](https://poppler.freedesktop.org/) and the cpp API of poppler. We extract this information using a specific version of pdftools, reason why the package need a version of poppler > 0.89 as well as a recent version of pdftools. 

```{r}
poppler_output <- segmenteR::prepare_poppler_output(pdf_name)
head(poppler_output)
```

This information is used to identify the probable font of the section, by first looking at the font use for the words Reference and Acknowledgment, that usually appear in only one occurrence in scientific articles :

```{r}
font_section <- segmenteR::identify_font(poppler_output)
print(font_section)
```
Knowing this, we can know what sections are inside the articles and in which order they appear.
The list under is the sections title that the script will try to identify in the poppler output :

```{r}
list_of_sections <- list(
    c("Introduction", "INTRODUCTION"),
    c("Materials", "Material", "materials", "material", "MATERIALS", "MATERIAL"),
    c("Methods", "Method", "methods", "method", "METHODS", "METHOD"),
    c("Acknowledgements", "Acknowledgments", "ACKNOWLEDGEMENTS", "ACKNOWLEDGMENTS",
      "Acknowledgement", "Acknowledgment", "ACKNOWLEDGEMENT", "ACKNOWLEDGMENT"),
    c("References", "REFERENCES"),
    c("Results", "RESULTS"),
    c("Discussion", "DISCUSSION", "discussion"),
    c("Abstract", "ABSTRACT"),
    c("Conclusions", "Conclusion", "CONCLUSION", "CONCLUSIONS"),
    c("Background", "BACKGROUND"),
    c("Experimental", "EXPERIMENTAL", "Experiment"),
    c("Supplementary", "SUPPLEMENTARY"),
    c("Methodology"),
    c("Appendix"),
    c("Section", "SECTION")
  )
```

Clean_font_txt() remove the most common font inside the articles, which improve the correct localization of the sections inside the pdf by create_section_title_df().

```{r}
poppler_output <- segmenteR::clean_font_txt(poppler_output)
head(poppler_output)
```

section_title_df is a dataframe with that contain the section titles in the articles and their relative order, based on the fonts information retrieved from the pdf. This informations (order and existence) will be used to localize the section in the ConLL-U format. This step is needed as the order and the composition of the sections title can change from one article to the other.

```{r}
section_title_df <- segmenteR::create_section_title_df(font_section, list_of_sections, poppler_output)
section_title_df <- segmenteR::clean_title_journal(pdf_name, section_title_df)
section_title_df <- segmenteR::ad_hoc_reorder(section_title_df)
head(section_title_df)
```

Removing the bibliography prevent some error in the localization in some sections, especially if a reference start with the word "material". This option can be set to false.

```{r}
if (remove_bibliography == TRUE) {
  conllu_df <- segmenteR::remove_bibliography_from_conllu(conllu_df, section_title_df)
  section_title_df <- segmenteR::remove_reference_section_from_titles(section_title_df)
}
```

Knowing the relative order of the sections from one side, and their name and having the information from the Conll-U dataframe, such as the position inside the sentence, or the other words in the sentence, we can estimate the position of the different sections inside the Conll-U dataframe. Please note that the positions_sections_df is not the section_title_df, and that the position number (occurrences) of the position is different, since section_title_df refer to the positions inside the output from poppler, while section_title_df indicate the positions inside the Conll-U dataframe.

```{r}
positions_sections_df <- segmenteR::locate_sections_position_in_conllu(conllu_df, section_title_df)
segmenteR::check_sections_df(positions_sections_df)
head(positions_sections_df)
```
Finally, knowing the positions of the sections, we can extract from the Conll-U dataframe the section we need. Extract_section_from_conllu() provide the section in ConLL-U format inside the dataframe section.


```{r}
section <- segmenteR::extract_section_from_conllu(conllu_df, positions_sections_df, section_aliases)
head(section)
```

